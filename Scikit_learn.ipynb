{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUecg7G24P2JImt3WDFpOO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WinstonMuijs/Natural-Language-Processing/blob/main/Scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0dzPMgcmDrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 'Bouwen van woord-vectoren in scikit learn'"
      ],
      "metadata": {
        "id": "UA5rftvRkzfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   verzamelen en preprocessen data\n",
        "2.   bepalen label\n",
        "3.   splitten van data in train en test\n",
        "4.   Features van de tekst eruit halen in de vorm van een BOW-vector, als input, om voorspellingen te kunnen doen.\n",
        "5.   evaluatie getraind model.\n",
        "\n"
      ],
      "metadata": {
        "id": "5jFyu-QPlZX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importeren van Pandas en Scikit Learn modules"
      ],
      "metadata": {
        "id": "I9n7-rAugjTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxAAM82DclLX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FYRaQKlqcqvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "vnh0IYoBc1vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creeren van een DataFrame op basis van een csv-file"
      ],
      "metadata": {
        "id": "DaTpExMTgonH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"fake_or_real_news.csv\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnvhphQ3c-66",
        "outputId": "54a13749-ac6c-476e-d3ea-e7f8bb2c178f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0                                              title  \\\n",
            "0           8476                       You Can Smell Hillary’s Fear   \n",
            "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
            "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
            "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
            "4            875   The Battle of New York: Why This Primary Matters   \n",
            "...          ...                                                ...   \n",
            "6330        4490  State Department says it can't find emails fro...   \n",
            "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
            "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
            "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
            "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
            "\n",
            "                                                   text label  \n",
            "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
            "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
            "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
            "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
            "4     It's primary day in New York and front-runners...  REAL  \n",
            "...                                                 ...   ...  \n",
            "6330  The State Department told the Republican Natio...  REAL  \n",
            "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
            "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
            "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
            "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
            "\n",
            "[6335 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gJghgY_hgu7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De labels vormen de ouput van het model. Het zijn de labels die je wilt dat het model levert of voorspelt. "
      ],
      "metadata": {
        "id": "meIPvdkOhhqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.label"
      ],
      "metadata": {
        "id": "IHKgpZcidfFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Je splitst je dataset in een train- en testset en je zegt dat de input-waarden van het model de tekstfeatures (rijen) zijn van de DataFrame, de output waarden y, en dat je de set verdeelt voor 33% in test en 66% in train data."
      ],
      "metadata": {
        "id": "Ja6lGV8fh5ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test , y_train, y_test = train_test_split(df['text'], y, test_size = 0.33, random_state = 53)"
      ],
      "metadata": {
        "id": "o1JkpFnmdv8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tekst wordt omgezet in een Bag of Words vector, net als een corpus in gensim. Een corpus transformeert een document in een Bag of Words door token id's en de frequentie van de woorden - tokens - in het document te nemen en deze in een lijst met tuples weer te geven. [[(id, freq,), (id, freq) ,(id, freq) ]] \n",
        "CountVectorizer doet ongeveer hetzelfde en een bag of words vector, waarbij elke token een feature is."
      ],
      "metadata": {
        "id": "xDApu7hJiqd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(stop_words = 'english')"
      ],
      "metadata": {
        "id": "0zO9_Et3eOJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Er wordt nu een BOW-vector gemaakt van de trainingsdata: mapping van de woorden met id's en vectoren hoeveel x een woord verschijnt in de tekst."
      ],
      "metadata": {
        "id": "jI97JNXRj2ZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_train = count_vectorizer.fit_transform(X_train.values)"
      ],
      "metadata": {
        "id": "xM0CiprpeXlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ook voor de test data"
      ],
      "metadata": {
        "id": "UU7LaMf8kXag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_test = count_vectorizer.transform(X_test.values)"
      ],
      "metadata": {
        "id": "OgpGQ5-NfzEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TmgoaI6Rka_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 5 features of the count_vectorizer\n",
        "print(count_vectorizer.get_feature_names_out()[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nrjBq87f9El",
        "outputId": "3ef78b30-a2b2-48fe-f960-7bc10518fdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['00' '000' '0000' '00000031' '000035']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TfidfVectorizer gebruikt ipv CountVectorizer"
      ],
      "metadata": {
        "id": "L6lX9eyEUZeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
        "\n",
        "# Transform the training data: tfidf_train \n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values)\n",
        "\n",
        "# Transform the test data: tfidf_test \n",
        "tfidf_test = tfidf_vectorizer.transform(X_test.values)\n",
        "\n",
        "# Print the first 10 features\n",
        "print(tfidf_vectorizer.get_feature_names()[:10])\n",
        "\n",
        "# Print the first 5 vectors of the tfidf training data\n",
        "print(tfidf_train.A[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2TwnG0RUZDE",
        "outputId": "13258aee-2dd9-4dac-c607-59c35a97282a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    }
  ]
}